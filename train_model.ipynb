{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3985d5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import layers, models, callbacks\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2d03706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (203000, 28, 28, 1), y: (203000,)\n"
     ]
    }
   ],
   "source": [
    "categories = [\n",
    "    'aircraft carrier', 'airplane', 'ambulance', 'ant', 'anvil',\n",
    "    'apple', 'axe', 'backpack', 'banana', 'baseball bat', 'baseball',\n",
    "    'bat', 'bear', 'bed', 'bee', 'belt', 'bench', 'bird', 'book',\n",
    "    'boomerang', 'bowtie', 'brain', 'bread', 'broom', 'bucket',\n",
    "    'bulldozer', 'bus', 'The Eiffel Tower', 'The Mona Lisa'\n",
    "]\n",
    "\n",
    "data_path = './data/'\n",
    "\n",
    "samples_per_category = 7000\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i, cat in enumerate(categories):\n",
    "    file_path = os.path.join(data_path, f'full_numpy_bitmap_{cat}.npy')\n",
    "    data = np.load(file_path)\n",
    "    data = data[:samples_per_category]\n",
    "    X.append(data)\n",
    "    y.append(np.full(len(data), i))\n",
    "\n",
    "X = np.concatenate(X).reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "y = np.concatenate(y)\n",
    "\n",
    "indices = np.arange(X.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "X, y = X[indices], y[indices]\n",
    "\n",
    "\n",
    "print(f'X: {X.shape}, y: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "354fae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f27aa7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Input(shape=(28, 28, 1)),\n",
    "\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPool2D((2, 2)),\n",
    "\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPool2D((2, 2)),\n",
    "\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "\n",
    "    layers.Dense(len(categories), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4dbabc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1269/1269 [==============================] - 82s 64ms/step - loss: 1.3203 - accuracy: 0.6251 - val_loss: 0.8455 - val_accuracy: 0.7634 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "1269/1269 [==============================] - 113s 89ms/step - loss: 0.8488 - accuracy: 0.7611 - val_loss: 0.7617 - val_accuracy: 0.7841 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "1269/1269 [==============================] - 117s 92ms/step - loss: 0.7589 - accuracy: 0.7880 - val_loss: 0.6818 - val_accuracy: 0.8100 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "1269/1269 [==============================] - 124s 98ms/step - loss: 0.7102 - accuracy: 0.8016 - val_loss: 0.6942 - val_accuracy: 0.8028 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "1269/1269 [==============================] - 131s 103ms/step - loss: 0.6804 - accuracy: 0.8114 - val_loss: 0.6326 - val_accuracy: 0.8222 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "1269/1269 [==============================] - 117s 92ms/step - loss: 0.6536 - accuracy: 0.8185 - val_loss: 0.6520 - val_accuracy: 0.8152 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "1269/1269 [==============================] - 119s 94ms/step - loss: 0.6357 - accuracy: 0.8232 - val_loss: 0.6639 - val_accuracy: 0.8139 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "1269/1269 [==============================] - 121s 96ms/step - loss: 0.6211 - accuracy: 0.8269 - val_loss: 0.5878 - val_accuracy: 0.8355 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "1269/1269 [==============================] - 119s 94ms/step - loss: 0.6113 - accuracy: 0.8307 - val_loss: 0.5619 - val_accuracy: 0.8442 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "1269/1269 [==============================] - 119s 94ms/step - loss: 0.5993 - accuracy: 0.8332 - val_loss: 0.5671 - val_accuracy: 0.8412 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "1269/1269 [==============================] - 117s 92ms/step - loss: 0.5936 - accuracy: 0.8353 - val_loss: 0.5880 - val_accuracy: 0.8370 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "1269/1269 [==============================] - 120s 95ms/step - loss: 0.5848 - accuracy: 0.8376 - val_loss: 0.5550 - val_accuracy: 0.8464 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "1269/1269 [==============================] - 118s 93ms/step - loss: 0.5775 - accuracy: 0.8394 - val_loss: 0.5578 - val_accuracy: 0.8461 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "1269/1269 [==============================] - 119s 94ms/step - loss: 0.5755 - accuracy: 0.8396 - val_loss: 0.5419 - val_accuracy: 0.8489 - lr: 0.0010\n",
      "Epoch 15/30\n",
      "1269/1269 [==============================] - 126s 99ms/step - loss: 0.5666 - accuracy: 0.8426 - val_loss: 0.5583 - val_accuracy: 0.8446 - lr: 0.0010\n",
      "Epoch 16/30\n",
      "1269/1269 [==============================] - 129s 102ms/step - loss: 0.5625 - accuracy: 0.8438 - val_loss: 0.5722 - val_accuracy: 0.8416 - lr: 0.0010\n",
      "Epoch 17/30\n",
      "1269/1269 [==============================] - 138s 109ms/step - loss: 0.5580 - accuracy: 0.8455 - val_loss: 0.5220 - val_accuracy: 0.8543 - lr: 0.0010\n",
      "Epoch 18/30\n",
      "1269/1269 [==============================] - 172s 136ms/step - loss: 0.5533 - accuracy: 0.8465 - val_loss: 0.5612 - val_accuracy: 0.8437 - lr: 0.0010\n",
      "Epoch 19/30\n",
      "1269/1269 [==============================] - 153s 120ms/step - loss: 0.5514 - accuracy: 0.8469 - val_loss: 0.5254 - val_accuracy: 0.8545 - lr: 0.0010\n",
      "Epoch 20/30\n",
      "1269/1269 [==============================] - 124s 97ms/step - loss: 0.5462 - accuracy: 0.8485 - val_loss: 0.5232 - val_accuracy: 0.8541 - lr: 0.0010\n",
      "Epoch 21/30\n",
      "1269/1269 [==============================] - 126s 99ms/step - loss: 0.5249 - accuracy: 0.8548 - val_loss: 0.4902 - val_accuracy: 0.8635 - lr: 5.0000e-04\n",
      "Epoch 22/30\n",
      "1269/1269 [==============================] - 128s 101ms/step - loss: 0.5165 - accuracy: 0.8571 - val_loss: 0.4992 - val_accuracy: 0.8602 - lr: 5.0000e-04\n",
      "Epoch 23/30\n",
      "1269/1269 [==============================] - 136s 107ms/step - loss: 0.5143 - accuracy: 0.8568 - val_loss: 0.4856 - val_accuracy: 0.8654 - lr: 5.0000e-04\n",
      "Epoch 24/30\n",
      "1269/1269 [==============================] - 116s 92ms/step - loss: 0.5097 - accuracy: 0.8573 - val_loss: 0.4888 - val_accuracy: 0.8650 - lr: 5.0000e-04\n",
      "Epoch 25/30\n",
      "1269/1269 [==============================] - 110s 87ms/step - loss: 0.5087 - accuracy: 0.8586 - val_loss: 0.4854 - val_accuracy: 0.8654 - lr: 5.0000e-04\n",
      "Epoch 26/30\n",
      "1269/1269 [==============================] - 115s 91ms/step - loss: 0.5061 - accuracy: 0.8590 - val_loss: 0.4919 - val_accuracy: 0.8644 - lr: 5.0000e-04\n",
      "Epoch 27/30\n",
      "1269/1269 [==============================] - 115s 91ms/step - loss: 0.5047 - accuracy: 0.8595 - val_loss: 0.4984 - val_accuracy: 0.8623 - lr: 5.0000e-04\n",
      "Epoch 28/30\n",
      "1269/1269 [==============================] - 118s 93ms/step - loss: 0.5025 - accuracy: 0.8596 - val_loss: 0.4833 - val_accuracy: 0.8661 - lr: 5.0000e-04\n",
      "Epoch 29/30\n",
      "1269/1269 [==============================] - 138s 108ms/step - loss: 0.5005 - accuracy: 0.8615 - val_loss: 0.4832 - val_accuracy: 0.8675 - lr: 5.0000e-04\n",
      "Epoch 30/30\n",
      "1269/1269 [==============================] - 150s 119ms/step - loss: 0.5015 - accuracy: 0.8601 - val_loss: 0.4848 - val_accuracy: 0.8661 - lr: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_gen = datagen.flow(X,y, batch_size=128, subset='training')\n",
    "val_gen = datagen.flow(X,y,batch_size=128, subset='validation')\n",
    "\n",
    "lr_reducer = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "early_stopper = callbacks.EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    validation_split=0.2,\n",
    "    epochs=30,\n",
    "    batch_size=128,\n",
    "    callbacks=[lr_reducer, early_stopper]\n",
    ")\n",
    "\n",
    "model.save('draw-ai/models/temp_model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
